# Первая Лаба 

 ## img_bgr = cv2.imread()
    
   Используется функция cv2.imread из библиотеки OpenCV для чтения изображения по указанному пути.
    cv2.imread возвращает изображение в формате массива NumPy, где каждый элемент соответствует пикселю.
    По умолчанию OpenCV загружает изображение в цветовом формате BGR (синий, зеленый, красный).
    


 ## image_dimmed = (img_bgr / 3).astype(np.uint8)
    
   Эта строка затемняет изображение, разделяя значения каждого пикселя на 3.
     (img_bgr / 3) уменьшает интенсивность цвета каждого канала (B, G, R).
     .astype(np.uint8) приводит результат к типу uint8 (целые числа от 0 до 255), который требуется для изображений.
     

 ## img_bgr2hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)
    
    используется функция cv2.cvtColor для преобразования изображения из цветового пространства BGR (синий, зеленый, красный) в HSV (оттенок, насыщенность, яркость).
    Цветовое пространство HSV часто используется в обработке изображений, поскольку оно отделяет цвет (Hue) от яркости (Value), что упрощает задачи, такие как выделение цветов.
 
 ## cv2_imshow(img_bgr2hsv)
  Показывает преобразованное изображение в формате HSV.
 
  Однако  в HSV-формате изображение может отображаться некорректно, поскольку оно рассчитано на внутреннее использование в обработке, а не для визуализации.


 ## img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
 
   Конвертирует изображение из формата BGR в RGB. OpenCV по умолчанию использует формат BGR, а для корректной визуализации в большинстве библиотек (например, Matplotlib) нужен формат RGB.
 
 ## img_rgb2hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)
 
   Конвертирует изображение из формата RGB в HSV. HSV (Hue, Saturation, Value) позволяет легче работать с цветами, выделяя их оттенок (Hue), насыщенность (Saturation) и яркость (Value).

 ## h, s, v = img_rgb2hsv[70, 70]

 Извлекает значения оттенка (h), насыщенности (s) и яркости (v) для пикселя в координатах (70, 70) из изображения в формате HSV.



 ## Преобразование в формат с плавающей запятой

 1. img_rgb_float = img_rgb / 255.0
  Нормализует RGB-значения изображения в диапазон [0, 1].
 2. r, g, b = img_rgb_float[:, :, 0], img_rgb_float[:, :, 1], img_rgb_float[:, :, 2]
  Разделяет нормализованное изображение на три компонента: r (красный), g (зеленый) и b (синий).

## Вычисление компонентов HSV

 3. v = np.max(img_rgb_float, axis=2)
  Определяет максимальное значение интенсивности (яркость, v) для каждого пикселя.
 4. min = np.min(img_rgb_float, axis=2)
  Определяет минимальное значение интенсивности для каждого пикселя.
 5. s = np.where(v == 0, 0, (v - min) / v)
  Вычисляет насыщенность (s) как разницу между максимальной и минимальной интенсивностью, деленную на v.
  Если v = 0, насыщенность устанавливается в 0, чтобы избежать деления на ноль.
 6. h = np.zeros_like(r)
  Создает массив h (оттенок) такой же формы, как канал r, заполненный нулями.

## Определение масок для цвета

 7. mask_r = v == r
  Создает логическую маску для пикселей, где максимальная интенсивность соответствует красному каналу.
 8. mask_g = v == g
  Аналогично, для зеленого канала.
 9. mask_b = v == b
  Аналогично, для синего канала.

## Вычисление оттенка (Hue)

 10. h[mask_r] = 60 * (g[mask_r] - b[mask_r]) / (v[mask_r] - min[mask_r])
  Вычисляет оттенок для пикселей, где красный доминирует. Формула основана на разнице между зелеными и синими значениями.
 11. h[mask_g] = 120 + 60 * (b[mask_g] - r[mask_g]) / (v[mask_g] - min[mask_g])
  Вычисляет оттенок для пикселей, где зеленый доминирует.
 12. h[mask_b] = 240 + 60 * (r[mask_b] - g[mask_b]) / (v[mask_b] - min[mask_b])
  Вычисляет оттенок для пикселей, где синий доминирует.
 13. h = np.where(h < 0, h + 360, h)
  Если оттенок отрицательный, добавляется 360 градусов.
 14. h = h / 2
  Приводит оттенок в диапазон [0, 180], используемый в OpenCV.

## Конвертация насыщенности и яркости

 15. s = 255 * s
  Масштабирует насыщенность в диапазон [0, 255].
 16. v = 255 * v
  Масштабирует яркость в диапазон [0, 255].

## Создание HSV-изображения

 17. hsv_arr = np.stack([h, s, v], axis=-1).astype(np.uint8)
  Объединяет компоненты h, s и v в одно изображение в формате HSV с целыми числами (uint8).
 18. cv2_imshow(hsv_arr)
  Отображает преобразованное изображение.

## Анализ пикселя

 19. h, s, v = hsv_arr[70, 70]
  Извлекает значения оттенка (h), насыщенности (s) и яркости (v) для пикселя в координате (70, 70).
 20. print(f"H: {h}, S: {s}, V: {v}")
  Выводит значения H, S и V для заданного пикселя.

# Вторая Лаба

   
## image_inter_area = cv2.resize(image, (0, 0), fx=3, fy=3, interpolation=cv2.INTER_AREA)
 
    Масштабирует изображение, увеличивая его размер в 3 раза по горизонтали (fx=3) и вертикали (fy=3).
 
    Используется метод интерполяции cv2.INTER_AREA, подходящий для уменьшения или высокого качества увеличения.

## print(image_inter_area[55][55])
 
    Выводит значение пикселя на позиции (55, 55) в увеличенном изображении.
 
    Значение пикселя — массив [B, G, R], где B — синий, G — зеленый, R — красный компоненты.

## resize_k_x = 3 и resize_k_y = 3
 
    Указывают коэффициенты масштабирования по горизонтали и вертикали (увеличение в 3 раза).
 
## blank_image = np.zeros((image.shape[0] * resize_k_x, image.shape[1] * resize_k_y, image.shape[2]), np.uint8)
 
    Создает пустое изображение (blank_image) с увеличенными размерами (в 3 раза по обеим осям) и тем же количеством каналов.
 
    Используется np.zeros для заполнения массива нулями (черный фон).
 
## Двойной цикл по строкам и столбцам:

       for row in range(image.shape[0]): 
           for col in range(image.shape[1]):

    Проходит по всем пикселям оригинального изображения.

 
## blank_image[row*resize_k_x][col*resize_k_y] = image[row][col]
 
    Устанавливает цвет пикселя из исходного изображения в соответствующую позицию увеличенного.
 
## Вложенный цикл:

       for res_row in range(resize_k_x): 
           for res_col in range(resize_k_y):
               blank_image[row*resize_k_x + res_row][col*resize_k_y + res_col] = image[row][col]

    Заполняет все пиксели вокруг основной точки, дублируя цвет исходного пикселя для масштабирования.

Код вручную масштабирует изображение путем дублирования пикселей, создавая эффект увеличения. Полученное изображение сравнивается с масштабированным изображением, созданным функцией OpenCV. 
 
## image_lin_intr = cv2.resize(image_lin_intr, (0, 0), fx=3, fy=3, interpolation=cv2.INTER_LINEAR)
 
    Масштабирует изображение в 3 раза по горизонтали и вертикали с использованием интерполяции cv2.INTER_LINEAR. Этот метод применяется для более плавных изменений размера, что может создавать более качественные результаты по сравнению с cv2.INTER_AREA.

**Метод cv2.INTER_LINEAR использует линейную интерполяцию для вычисления новых пикселей, что делает изображение более четким по сравнению с cv2.INTER_AREA**

**Установка коэффициентов масштабирования**
koef_x = 3
koef_y = 3

## Извлечение размеров изображения

height, width = image.shape[:2]

## Рассчет нового размера изображения

new_height = int(height * koef_y)

new_width = int(width * koef_x)

**Создание пустого массива для результата**

result = np.zeros((new_height, new_width, image.shape[2]), dtype=image.dtype)

## Циклы для каждого пикселя результата

    for y in range(new_height):
        for x in range(new_width):
            original_y = y / koef_y
            original_x = x / koef_x

        y_low = math.floor(original_y)
        x_low = math.floor(original_x)

        y_frac = original_y - y_low
        x_frac = original_x - x_low

        # Ограничение координат для соседей пикселя
        y_low = max(0, min(y_low, height - 2))
        x_low = max(0, min(x_low, width - 2))

        y_high = min(height - 1, y_low + 1)
        x_high = min(width - 1, x_low + 1)

        # Билинейная интерполяция
        for c in range(image.shape[2]):
            val_low = image[y_low, x_low, c]
            val_high = image[y_high, x_low, c]
            val_low2 = image[y_low, x_high, c]
            val_high2 = image[y_high, x_high, c]

            result[y, x, c] = (1 - y_frac) * (1 - x_frac) * val_low + (y_frac) * (1 - x_frac) * val_high + (1 - y_frac) * (x_frac) * val_low2 + (y_frac) * (x_frac) * val_high2

## Карта пространственой частоты изображения
обработка изображения в частотной области, включая применение оконной функции Ханна, вычисление спектра Фурье, и визуализацию карты пространственных частот.

 1. Чтение изображения в градациях серого:

image = cv2.imread()
rows, cols = image.shape


 2. Создание 2D-окна Ханна:

window_2d = np.outer(windows.hann(rows), windows.hann(cols))
windowed_img = image * window_2d

Окно Ханна применяется для уменьшения эффекта утечки спектра при преобразовании Фурье.

 3. Прямое преобразование Фурье:
    
      dft = np.fft.fft2(windowed_img)
      dft_shift = np.fft.fftshift(dft)
      magnitude_spectrum = np.abs(dft_shift)


 5. Логарифмическая визуализация:

spatial_frequency_map = np.log1p(magnitude_spectrum)
cv2_imshow(spatial_frequency_map)

Логарифм улучшает отображение, компенсируя большую разницу между высокими и низкими частотами.

 Карта пространственных частот изображения, показывает области с высокой и низкой интенсивностью спектра.
# Лаба 3
# Лаба 4
## Функция вычисления градиентов

Описание функции:

Функция compute_gradients вычисляет пространственные и временные градиенты между двумя изображениями I1 (текущее изображение) и I2 (следующее изображение). Это полезно для задач, связанных с обработкой изображений, таких как оценка оптического потока.

Код:

def compute_gradients(I1, I2):
    Ix = cv2.Sobel(I1, cv2.CV_64F, 1, 0, ksize=5)  # Горизонтальный градиент
    Iy = cv2.Sobel(I1, cv2.CV_64F, 0, 1, ksize=5)  # Вертикальный градиент
    It = I2 - I1  # Временной градиент
    return Ix, Iy, It

Параметры:

 • I1: Первое изображение (в градациях серого).
 • I2: Второе изображение (в градациях серого).

Вычисления:

 1. Горизонтальный градиент (Ix):
Использует оператор Собеля для определения изменений интенсивности вдоль оси X.
 2. Вертикальный градиент (Iy):
Определяет изменения вдоль оси Y с помощью оператора Собеля.
 3. Временной градиент (It):
Разница между вторым и первым изображением показывает изменения во времени.

Возвращаемые значения:

  Ix: Горизонтальный градиент.
  Iy: Вертикальный градиент.
  It: Временной градиент.

Эта функция используется для оценки движения между двумя последовательными кадрами или изображениями
 ## Оптический поток Лукаса-Канаде

Описание функции:

Функция lucas_kanade_optical_flow реализует метод Лукаса-Канаде для оценки оптического потока между двумя последовательными изображениями. Она вычисляет вектор движения для каждого пикселя, основываясь на локальных градиентах изображения.

Код:

def lucas_kanade_optical_flow(I1, I2, window_size=5):
    Ix, Iy, It = compute_gradients(I1, I2)  
    cv2_imshow(Ix)  
    cv2_imshow(Iy)  
    cv2_imshow(It)  

    half_window = window_size // 2
    h, w = I1.shape
    flow = np.zeros((h, w, 2))  

    for y in range(half_window, h - half_window):
        for x in range(half_window, w - half_window):
            Ix_window = Ix[y - half_window:y + half_window + 1, x - half_window:x + half_window + 1].flatten()
            Iy_window = Iy[y - half_window:y + half_window + 1, x - half_window:x + half_window + 1].flatten()
            It_window = It[y - half_window:y + half_window + 1, x - half_window:x + half_window + 1].flatten()

            M = np.vstack((Ix_window, Iy_window)).T  
            b = -It_window  

            if np.linalg.matrix_rank(M) == 2:  
                nu = np.linalg.lstsq(M, b, rcond=None)[0]  
                flow[y, x] = nu  
    print(flow.shape)

    return flow

Параметры:

  I1: Первое изображение (градации серого).
  I2: Второе изображение (градации серого).
  window_size: Размер окна (по умолчанию 5), определяет область анализа для каждого пикселя.

Основные шаги:

 1. Вычисление градиентов:
  Ix и Iy — пространственные градиенты (горизонтальные и вертикальные изменения).
  It — временной градиент (разница между изображениями).
 2. Локальная обработка окна:
  Для каждого пикселя определяется окно размером window_size × window_size.
  Вычисляются локальные градиенты и составляются матрица  и вектор .
 3. Решение системы уравнений:
  Решается система , где  — вектор движения.
 4. Результат:
  Возвращается поле векторов движения (оптический поток) размером .

Возвращаемое значение:

  flow: Трехмерный массив, где каждый вектор  представляет движение пикселя по осям X и Y.

Метод используется для анализа движения в последовательностях изображений, таких как видео, например, для трекинга объектов.
# Лаба 5
## Функция sigmoid(x) 
вычисляет сигмоидальную активацию для входного значения . Она описывается формулой:
σ(x) = 1 / (1 + exp(-x))


Основные особенности:
 1. Выходной диапазон: Значения функции находятся в диапазоне (0;1) .
 2. Применение:
    
  В машинном обучении используется для преобразования выходных данных в вероятности (например, в логистической регрессии).

  В нейронных сетях — как функция активации для нелинейности.
## Функция sigmoid_der(x)
Рассчитывает производную функции сигмоиды

Показывает скоростьизменения сигмоиды в зависимости от x
## relu(x)
Функция relu(x) применяется для вычисления функции активации ReLU (Rectified Linear Unit). Она возвращает максимум из нуля и , что позволяет нейронной сети пропускать только положительные значения через себя, исключая отрицательные.
## def forward_propagation(x, w1, b1, w2, b2, w3, b3):
Функция forward_propagation(x, w1, b1, w2, b2, w3, b3) выполняет вычисления для трех слоев сети. Входные данные x проходят через каждый слой, применяя операции линейного преобразования и функции активации ReLU, а затем получают результаты в виде z1, a1, z2, a2, z3, и a3. z1 и z2 – это линейные комбинации входов и весов с добавлением смещений, a1 и a2 – активации после ReLU, а a3 – финальная активация сигмоид.
## Функция cross_entropy_loss_derivative(y_true, y_pred)
Функция cross_entropy_loss_derivative(y_true, y_pred) вычисляет производную кросс-энтропийной потери для вектора предсказанных значений y_pred относительно истинных значений y_true. Вводимые значения y_pred подстраиваются для предотвращения деления на ноль с помощью np.clip. Результат представляет собой производную потери, которая используется для обновления весов в нейронной сети во время обучения.
## Функция backward_propagation
Функция backward_propagation вычисляет градиенты весов и смещений для каждого слоя в нейронной сети. Она принимает входные данные x, истинные значения y, а также предсказания и промежуточные результаты z1, a1, z2, a2, z3, a3. Вычисляет градиенты для веса и смещений каждого слоя с использованием производных функции потерь и активации. Эти градиенты используются для обновления весов в процессе обучения сети.
## Функция initialize_parameters
Функция initialize_parameters создает случайные веса и нулевые смещения для сети, принимая размеры слоев входного слоя (inp_layer), первого скрытого слоя (hid_layer_1), второго скрытого слоя (hid_layer_2), и выходного слоя (out_layer). Весы генерируются случайными числами с нормальным распределением, умноженными на 0.01 для нормализации. Смещения (b1, b2, b3) инициализируются нулями.
## Функция cross_entropy_loss
Функция cross_entropy_loss вычисляет потерю, которую модель делает при её предсказаниях. Она сравнивает истинные метки (y_true) и прогнозируемые значения (y_pred). Чтобы избежать ошибок, связанных с логарифмом, она ограничивает значения предсказаний между очень маленькими и близкими к 1. Формула вычисляет среднеквадратическую разницу между истинными и прогнозируемыми значениями, что помогает улучшить точность модели.
## Функция train_network
Функция train_network обучает нейронную сеть, обновляя её параметры в процессе итераций. На каждом шаге сети выполняется расчет предсказаний и потерь, затем пересчитываются градиенты и обновляются веса и смещения, чтобы минимизировать ошибки. Каждый 10-й шаг обучения выводит значение потерь для отслеживания прогресса. На выходе функция возвращает обновленные параметры сети.
## Функция dataset()
 Загружает набор данных MNIST, нормализует значения пикселей до диапазона [0, 1] и применяет one-hot encoding к меткам как для обучающей, так и для тестовой выборки перед возвратом.
